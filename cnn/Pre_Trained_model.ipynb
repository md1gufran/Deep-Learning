{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Pre Trained Model in Deep Learning\n",
        "In transfer Learning we import a Model which is already Trained Like Resnet50 in this we will have\n",
        "Convolution Layer + Feed Forward Layer + Dense.\n",
        "In this we fix the weights of Convolution Layer and we train only just Dense Layer. For our specific Dataset. In Fine-Tuning we take some Convolution Layer + Dense Layer for training."
      ],
      "metadata": {
        "id": "aILsP5Vkurpv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XqfIxNnysgng"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "SJxrKsl0uh0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IzO-RKEwjod",
        "outputId": "4e701b72-d67f-42a2-89ff-fc6613232a8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 98% 1.05G/1.06G [00:09<00:00, 95.8MB/s]\n",
            "100% 1.06G/1.06G [00:09<00:00, 121MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "SzLGNPafxeSn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Flatten,Dense\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "metadata": {
        "id": "UnGtwjMAyAoM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have Loaded VGG16 Model which is trained on imagenet Dataset. And include_top = False ( Imply We will fix all the Convolution Layer And we Just edit Dense Layer )"
      ],
      "metadata": {
        "id": "Mf3HscFX4JXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(\n",
        "    weights = 'imagenet',\n",
        "    include_top = False,\n",
        "    input_shape = (256,256,3)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5JtxVKjyR0c",
        "outputId": "78647c27-fa45-4c89-897d-59bb922b7ac0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "yunTFEK9yz0B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA8ZQraNzLe-",
        "outputId": "f61783ae-1e40-4831-c36b-8e9b16f92cbb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               8388864   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23103809 (88.13 MB)\n",
            "Trainable params: 23103809 (88.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.trainable = False"
      ],
      "metadata": {
        "id": "OJh4f_HpzPme"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/train',\n",
        "    labels = 'inferred',\n",
        "    label_mode='int', # It will asign 0-> to Dog and 1 to-> Cat\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)  # We are doing so inordere to make the image of all image to same level\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/test',\n",
        "    labels = 'inferred',\n",
        "    label_mode='int', # It will asign 0-> to Dog and 1 to-> Cat\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)  # We are doing so inordere to make the image of all image to same level\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TEEALzuzV_a",
        "outputId": "7c8826ab-287e-46c2-fd91-1b5b977d99d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "KoNvfrRV0dPe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(image,label):\n",
        "  image = tf.cast(image/255. ,tf.float32)\n",
        "  return image,label\n",
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)"
      ],
      "metadata": {
        "id": "tcMEd4OAz5g6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "cpXunxMV0kWO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds,epochs=10,validation_data=(validation_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVwCfcNa0tlN",
        "outputId": "615917c3-9d24-4dcb-9764-9027431257d8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 144s 212ms/step - loss: 0.2545 - accuracy: 0.9027 - val_loss: 0.1498 - val_accuracy: 0.9368\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 135s 216ms/step - loss: 0.1427 - accuracy: 0.9428 - val_loss: 0.1584 - val_accuracy: 0.9334\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 148s 236ms/step - loss: 0.0844 - accuracy: 0.9664 - val_loss: 0.1573 - val_accuracy: 0.9368\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 149s 237ms/step - loss: 0.0577 - accuracy: 0.9789 - val_loss: 0.1793 - val_accuracy: 0.9344\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 150s 240ms/step - loss: 0.0570 - accuracy: 0.9775 - val_loss: 0.2286 - val_accuracy: 0.9306\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 148s 237ms/step - loss: 0.0395 - accuracy: 0.9843 - val_loss: 0.4867 - val_accuracy: 0.8880\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 134s 214ms/step - loss: 0.0307 - accuracy: 0.9884 - val_loss: 0.2388 - val_accuracy: 0.9318\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 148s 236ms/step - loss: 0.0372 - accuracy: 0.9851 - val_loss: 0.2268 - val_accuracy: 0.9328\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 135s 215ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.2560 - val_accuracy: 0.9302\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 148s 237ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.2618 - val_accuracy: 0.9292\n"
          ]
        }
      ]
    }
  ]
}